{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  MentalHealth  \\\n124888  0.127731      No              No     No        0.066667      0.100000   \n221972  0.135458      No              No     No        0.000000      0.000000   \n254188  0.321140      No              No     No        0.000000      0.000000   \n56215   0.205602     Yes             Yes     No        0.000000      0.000000   \n256278  0.284317      No              No     No        0.000000      0.000000   \n...          ...     ...             ...    ...             ...           ...   \n180856  0.222262      No              No     No        0.000000      0.000000   \n8631    0.157431     Yes              No     No        0.000000      0.000000   \n113561  0.244597      No              No     No        0.166667      0.233333   \n279178  0.189424      No              No     No        0.000000      0.000000   \n160831  0.229265     Yes              No     No        0.000000      0.000000   \n\n       DiffWalking     Sex  AgeCategory   Race Diabetic PhysicalActivity  \\\n124888         Yes  Female        60-64  White       No               No   \n221972          No  Female        70-74  Black      Yes              Yes   \n254188          No  Female        45-49  White       No               No   \n56215          Yes  Female        70-74  White       No              Yes   \n256278          No    Male        35-39  White       No              Yes   \n...            ...     ...          ...    ...      ...              ...   \n180856          No    Male        30-34  White       No              Yes   \n8631            No  Female  80 or older  White       No              Yes   \n113561         Yes  Female        55-59  White       No              Yes   \n279178          No    Male        75-79  White       No              Yes   \n160831          No  Female        45-49  Other       No              Yes   \n\n        GenHealth  SleepTime Asthma KidneyDisease SkinCancer  \n124888  Excellent   0.217391     No            No         No  \n221972  Very good   0.391304     No            No         No  \n254188  Very good   0.260870     No            No         No  \n56215   Very good   0.347826     No            No         No  \n256278       Good   0.347826     No            No         No  \n...           ...        ...    ...           ...        ...  \n180856       Fair   0.347826     No            No         No  \n8631    Excellent   0.260870     No            No        Yes  \n113561       Good   0.304348     No            No        Yes  \n279178  Very good   0.304348     No            No         No  \n160831  Very good   0.260870     No            No         No  \n\n[15989 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI</th>\n      <th>Smoking</th>\n      <th>AlcoholDrinking</th>\n      <th>Stroke</th>\n      <th>PhysicalHealth</th>\n      <th>MentalHealth</th>\n      <th>DiffWalking</th>\n      <th>Sex</th>\n      <th>AgeCategory</th>\n      <th>Race</th>\n      <th>Diabetic</th>\n      <th>PhysicalActivity</th>\n      <th>GenHealth</th>\n      <th>SleepTime</th>\n      <th>Asthma</th>\n      <th>KidneyDisease</th>\n      <th>SkinCancer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124888</th>\n      <td>0.127731</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.066667</td>\n      <td>0.100000</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>60-64</td>\n      <td>White</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Excellent</td>\n      <td>0.217391</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>221972</th>\n      <td>0.135458</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>70-74</td>\n      <td>Black</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Very good</td>\n      <td>0.391304</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>254188</th>\n      <td>0.321140</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>45-49</td>\n      <td>White</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Very good</td>\n      <td>0.260870</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>56215</th>\n      <td>0.205602</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>70-74</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Very good</td>\n      <td>0.347826</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>256278</th>\n      <td>0.284317</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>35-39</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Good</td>\n      <td>0.347826</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>180856</th>\n      <td>0.222262</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>30-34</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Fair</td>\n      <td>0.347826</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>8631</th>\n      <td>0.157431</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>80 or older</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Excellent</td>\n      <td>0.260870</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>113561</th>\n      <td>0.244597</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.166667</td>\n      <td>0.233333</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>55-59</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Good</td>\n      <td>0.304348</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>279178</th>\n      <td>0.189424</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>75-79</td>\n      <td>White</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Very good</td>\n      <td>0.304348</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>160831</th>\n      <td>0.229265</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>45-49</td>\n      <td>Other</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Very good</td>\n      <td>0.260870</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>15989 rows Ã— 17 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "heart_dataset = pd.read_csv('heart_dataset_preprocessed.csv')\n",
    "\n",
    "# Split dataset\n",
    "heart_dataset_target = heart_dataset['HeartDisease']\n",
    "heart_dataset_data = heart_dataset.drop(columns='HeartDisease')\n",
    "\n",
    "# Make dataset smaller for testing\n",
    "heart_dataset_data, _, heart_dataset_target, _ = train_test_split(\n",
    "    heart_dataset_data, heart_dataset_target, test_size=0.95, random_state=42, stratify=heart_dataset_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "We define a baseline model as a reference to the actual model with DummyClassifier from Scikit-Learn. Because our data is very imbalanced, we are using the stratified strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.8369184592296148,\n 'recall': 0.09686609686609686,\n 'precision': 0.0921409214092141,\n 'f1_score': 0.09444444444444444}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# X_train: Includes all independent variables, these will be used to train the model; because test_size=0.3, only 70% of data will be used for training\n",
    "# X_test: Remaining 30% of the independent variables which will not be used in the training phase and will be used to make predictions to evaluate the model\n",
    "# y_train: Dependent variable which needs to be predicted by the model\n",
    "# y_test: This data has category labels for your test data, these labels will be used for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_dataset_data, heart_dataset_target, test_size = 0.3, random_state = 42)\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy='stratified')\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "y_predicted = dummy_classifier.predict(X_test)\n",
    "results_dict = {'accuracy': accuracy_score(y_test, y_predicted),\n",
    "                'recall': recall_score(y_test, y_predicted),\n",
    "                'precision': precision_score(y_test, y_predicted),\n",
    "                'f1_score': f1_score(y_test, y_predicted)}\n",
    "display(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conclusion**\n",
    "\n",
    "We achieve an 0.84 accuracy, a 0.09 recall, a 0.09 precision and a 0.09 F1-Score.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generic modelling and evaluation method\n",
    "\n",
    "Function that generate different models and evaluate them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "def model_eval(estimator, parameters, X, y, scoring=scorer, verbose=0):\n",
    "    # specify the cross validation\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    # create the grid search instance\n",
    "    grid_search_estimator = GridSearchCV(estimator=estimator,\n",
    "                                         param_grid=parameters,\n",
    "                                         scoring=scoring,\n",
    "                                         cv=inner_cv,\n",
    "                                         return_train_score=False,\n",
    "                                         verbose=verbose\n",
    "                                        )\n",
    "\n",
    "\n",
    "    nested_cv_score = cross_validate(grid_search_estimator,\n",
    "                                     X=X, y=y,\n",
    "                                     verbose=verbose,\n",
    "                                     cv=outer_cv, scoring=scorer)\n",
    "\n",
    "#     display(nested_cv_score.mean())\n",
    "    return nested_cv_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "12 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'No'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "12 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'No'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Yes'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "12 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'No'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "12 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'No'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "4 fits failed out of a total of 4.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\", line 891, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\", line 1392, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\", line 875, in evaluate_candidates\n",
      "    _insert_error_scores(out, self.error_score)\n",
      "  File \"/Users/benediktluth/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 331, in _insert_error_scores\n",
      "    raise NotFittedError(\"All estimators failed to fit\")\n",
      "sklearn.exceptions.NotFittedError: All estimators failed to fit\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "All estimators failed to fit",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# specify the parameter grid\u001B[39;00m\n\u001B[1;32m      7\u001B[0m parameters \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m5\u001B[39m]\n\u001B[1;32m      9\u001B[0m }\n\u001B[0;32m---> 11\u001B[0m knn_result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknn_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheart_dataset_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheart_dataset_target\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mmodel_eval\u001B[0;34m(estimator, parameters, X, y, scoring, verbose)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# create the grid search instance\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     grid_search_estimator \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m     15\u001B[0m                                          param_grid\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m     16\u001B[0m                                          scoring\u001B[38;5;241m=\u001B[39mscoring,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m                                          verbose\u001B[38;5;241m=\u001B[39mverbose\n\u001B[1;32m     20\u001B[0m                                         )\n\u001B[0;32m---> 23\u001B[0m     nested_cv_score \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid_search_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscorer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m#     display(nested_cv_score.mean())\u001B[39;00m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m nested_cv_score\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:292\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(scoring):\n\u001B[0;32m--> 292\u001B[0m     \u001B[43m_insert_error_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    294\u001B[0m results \u001B[38;5;241m=\u001B[39m _aggregate_score_dicts(results)\n\u001B[1;32m    296\u001B[0m ret \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:331\u001B[0m, in \u001B[0;36m_insert_error_scores\u001B[0;34m(results, error_score)\u001B[0m\n\u001B[1;32m    328\u001B[0m         successful_score \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m successful_score \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll estimators failed to fit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(successful_score, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    334\u001B[0m     formatted_error \u001B[38;5;241m=\u001B[39m {name: error_score \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m successful_score}\n",
      "\u001B[0;31mNotFittedError\u001B[0m: All estimators failed to fit"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create an estimator\n",
    "knn_estimator = KNeighborsClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': [2, 3, 5]\n",
    "}\n",
    "\n",
    "knn_result = model_eval(estimator=knn_estimator, parameters=parameters, X=heart_dataset_data, y=heart_dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.16398140810083794\n",
      "0.12616201859229748\n",
      "0.17739816031537448\n",
      "0.1762402088772846\n",
      "0.17612524461839527\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", knn_result['test_score'].mean())\n",
    "for score in knn_result['test_score']:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create an estimator\n",
    "forest_estimator = RandomForestClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_estimators': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "forest_result = model_eval(estimator=forest_estimator, parameters=parameters, X=heart_dataset_data, y=heart_dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.1806964458049986\n",
      "0.19626168224299068\n",
      "0.15842839036755388\n",
      "0.18873762376237624\n",
      "0.1793580868470736\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", forest_result['test_score'].mean())\n",
    "for score in forest_result['test_score']:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create an estimator\n",
    "svc_estimator = SVC(random_state=0)\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'poly']\n",
    "}\n",
    "\n",
    "svc_result = model_eval(estimator=svc_estimator, parameters=parameters, X=heart_dataset_data, y=heart_dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.07955710385257753\n",
      "0.07368421052631578\n",
      "0.07127583749109051\n",
      "0.07446808510638298\n",
      "0.0988002822865208\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", svc_result['test_score'].mean())\n",
    "for score in svc_result['test_score']:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# create an estimator\n",
    "nn_estimator = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "nn_result = model_eval(estimator=nn_estimator, parameters=parameters, X=heart_dataset_data, y=heart_dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.15287409227221466\n",
      "0.13494809688581316\n",
      "0.17749497655726723\n",
      "0.12732278045423262\n",
      "0.17173051519154559\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", nn_result['test_score'].mean())\n",
    "for score in nn_result['test_score']:\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
